{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "import ast\n",
    "import re\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation, CompoundLocation\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Align import AlignInfo\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a polymorphism frequency, return bin\n",
    "def frequency_binning(x, midfreq_high, midfreq_low):\n",
    "\n",
    "    #nan frequencies are when there is no sequence coverage at the given position\n",
    "    if math.isnan(x):\n",
    "        f_bin = float('nan')\n",
    "    else:\n",
    "        if x == 1.0:\n",
    "            f_bin = 'f'\n",
    "        elif x>=midfreq_high:\n",
    "            f_bin = 'h'\n",
    "        elif x<midfreq_high and x>=midfreq_low:\n",
    "            f_bin = 'm'\n",
    "        elif x<midfreq_low:\n",
    "            f_bin='l'\n",
    "\n",
    "    return f_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroup_seq_test = Seq('ATGAAACCCGGGTTTAAACCCGGG')\n",
    "outgroup_seq_aa_test = outgroup_seq_test.translate()\n",
    "alignment_seqs_test = [Seq('ATGAAGCCCGGGATTAAACCCGGG'),\n",
    "                  Seq('ATGAAGCCCGGGATTAAACCCGGG'),\n",
    "                  Seq('ATGAAGCCCGGGATTAAACCCGCG'),\n",
    "                  Seq('ATGAAGCCCGGGATTAAACCCGCG'),\n",
    "                  Seq('ATGAAGCCCGGGATTAAACCCGCG'), \n",
    "                  Seq('ATGAAGCCCGGGATTAAACCCGCG'), \n",
    "                  Seq('ATGAAGCCCGGGATTAAACCCGAG'), \n",
    "                  Seq('ATGAAGCCCGGGTTTAAACCCGAG'), \n",
    "                  Seq('ATGAAGCCCGGGTTTAAACCCGTA'), \n",
    "                  Seq('ATGAAACCCGGGTTTAAACCCGTA')]\n",
    "\n",
    "# walk_through_sites(outgroup_seq_test, outgroup_seq_aa_test, alignment_seqs_test, 0.75, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_sites(outgroup_seq, outgroup_aa_seq, alignment_seqs, midfreq_high, midfreq_low):\n",
    "\n",
    "    #at each site, count number of viruses with polymorphism\n",
    "    count_polymorphic = np.zeros(len(outgroup_seq))\n",
    "    #at each site, count totaly number of viruses\n",
    "    count_total_unambiguous = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    count_replacement_mutations = np.zeros(len(outgroup_seq))\n",
    "    count_silent_mutations = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    #at each site, list of nucleotide from each virus\n",
    "    ingroup_bases = [[] for x in range(len(outgroup_seq))]\n",
    "    \n",
    "    for seq in alignment_seqs:\n",
    "        if len(seq) != len(outgroup_seq):\n",
    "            print(len(seq), len(outgroup_seq))\n",
    "            print(seq)\n",
    "        elif len(seq) == len(outgroup_seq):                   \n",
    "            for pos in range(len(outgroup_seq)):\n",
    "                outgroup_nt = str(outgroup_seq[pos])\n",
    "                virus_nt = str(seq[pos])\n",
    "\n",
    "                #skip ambiguous sites\n",
    "#                 if virus_nt != 'N' and virus_nt != 'W':\n",
    "#                     if outgroup_nt != 'N' and outgroup_nt != 'W':\n",
    "                if virus_nt in ['A', 'C', 'G', 'T']:\n",
    "                    if outgroup_nt in ['A', 'C', 'G', 'T']:\n",
    "                        ingroup_bases[pos].append(virus_nt)\n",
    "                        count_total_unambiguous[pos]+=1\n",
    "                        if virus_nt != outgroup_nt:\n",
    "                            count_polymorphic[pos]+=1\n",
    "                            #determine silent or replacement\n",
    "                            codon = math.floor(pos/3)\n",
    "                            \n",
    "                            codon_pos = pos-(codon*3)\n",
    "                            if codon_pos == 0:\n",
    "                                codon_nt = virus_nt+outgroup_seq[pos+1:(pos+3)]\n",
    "                            elif codon_pos == 1:\n",
    "                                codon_nt = outgroup_seq[pos-1]+virus_nt+outgroup_seq[pos+1]\n",
    "                            elif codon_pos == 2:\n",
    "                                codon_nt = outgroup_seq[(pos-2):(pos)]+virus_nt\n",
    "\n",
    "                                \n",
    "                            if isinstance(codon_nt, str):\n",
    "                                codon_nt = Seq(codon_nt)\n",
    "\n",
    "                            codon_aa = codon_nt.translate()\n",
    "                            \n",
    "\n",
    "                            outgroup_aa = outgroup_aa_seq[codon]\n",
    "\n",
    "                            if outgroup_aa != 'X':\n",
    "                                if codon_aa != outgroup_aa:\n",
    "                                    count_replacement_mutations[pos]+=1\n",
    "                                elif codon_aa == outgroup_aa:\n",
    "                                    count_silent_mutations[pos]+=1\n",
    "                                                          \n",
    "    polymorphic_frequencies = count_polymorphic/count_total_unambiguous\n",
    "    \n",
    "    replacement_score = count_replacement_mutations/count_total_unambiguous\n",
    "\n",
    "    freq_bins = [frequency_binning(x, midfreq_high, midfreq_low) for x in polymorphic_frequencies]\n",
    "    \n",
    "    return freq_bins, replacement_score, ingroup_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_site_type(outgroup, ingroup):\n",
    "\n",
    "    ingroup_bases_nan = set(ingroup)\n",
    "    #remove 'nan's\n",
    "    ingroup_bases = {x for x in ingroup_bases_nan if pd.notna(x)}\n",
    "\n",
    "    \n",
    "    if len(ingroup_bases) == 0:\n",
    "        site_type = None\n",
    "    \n",
    "    elif len(ingroup_bases) != 0:\n",
    "        #all ingroup bases are identical\n",
    "        if len(ingroup_bases) == 1:\n",
    "            if outgroup in ingroup_bases:\n",
    "                site_type = 1\n",
    "            elif outgroup not in ingroup_bases:\n",
    "                site_type = 2\n",
    "\n",
    "        #2 different bases in ingroup\n",
    "        elif len(ingroup_bases) == 2:\n",
    "            if outgroup in ingroup_bases:\n",
    "                site_type = 3\n",
    "            elif outgroup not in ingroup_bases:\n",
    "                site_type = 4\n",
    "\n",
    "        #3 different bases in ingroup\n",
    "        elif len(ingroup_bases) == 3:\n",
    "            if outgroup in ingroup_bases:\n",
    "                site_type = 5\n",
    "            elif outgroup not in ingroup_bases:\n",
    "                site_type = 6\n",
    "\n",
    "        #4 different bases in ingroup\n",
    "        elif len(ingroup_bases) == 4:\n",
    "            site_type = 7\n",
    "    \n",
    "    \n",
    "    return site_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_polymorphism_score(outgroup, ingroup):\n",
    "    site_type = determine_site_type(outgroup, ingroup)\n",
    "\n",
    "    \n",
    "    if site_type == None:\n",
    "        Fi = float('nan')\n",
    "        Pi = float('nan')\n",
    "    if site_type == 1:\n",
    "        Fi = 0\n",
    "        Pi = 0\n",
    "    elif site_type == 2:\n",
    "        Fi = 1\n",
    "        Pi = 0\n",
    "    elif site_type in [3,5,7]:\n",
    "        Fi = 0\n",
    "        Pi = 1\n",
    "    elif site_type == 4:\n",
    "        Fi = 0.5\n",
    "        Pi = 0.5\n",
    "    elif site_type == 6:\n",
    "        Fi = (1/3)\n",
    "        Pi = (2/3)\n",
    "    \n",
    "    return Fi, Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fi_pi(outgroup_seq, ingroup_bases):\n",
    "    \n",
    "    #at each site, record Fi\n",
    "    Fi_all = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    #at each site, record Pi\n",
    "    Pi_all = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    for pos in range(len(outgroup_seq)):\n",
    "        outgroup_nt = outgroup_seq[pos]\n",
    "        ingroup_nts = ingroup_bases[pos]\n",
    "        Fi, Pi = fixation_polymorphism_score(outgroup_nt, ingroup_nts)\n",
    "        Fi_all[pos] = Fi\n",
    "        Pi_all[pos] = Pi\n",
    "        \n",
    "    return Fi_all, Pi_all\n",
    "    \n",
    "    \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readin_virus_config(virus):\n",
    "    config_json = f'config/adaptive_evo_config_{virus}.json'\n",
    "    with open(config_json) as json_handle:\n",
    "        configs = json.load(json_handle)\n",
    "        \n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_viruses_nextstrain_build(virus, subtype, gene, window, min_seqs, year_max, year_min):\n",
    "    \n",
    "    # whether to return alignment of the whole gene (excluding duplicated region), or just the dupicated region\n",
    "    alignment_to_return = 'main'\n",
    "    if '_duplication' in gene:\n",
    "        gene = str(gene[0])\n",
    "        alignment_to_return = 'duplication'\n",
    "    \n",
    "    configs = readin_virus_config(virus)\n",
    "    standard_gene = standardize_gene_name(virus, gene)\n",
    "    \n",
    "\n",
    "    #Find reference, alignment and meta files (some sub-genic regions may use files from a gene or a whole genome)\n",
    "    if 'specify_location' in configs[standard_gene].keys():\n",
    "        parent_gene = configs[standard_gene]['specify_location']['parent_gene']\n",
    "        reference_file = configs['reference_file'].format(virus=virus, subtype=subtype, gene=parent_gene)\n",
    "        alignment_file = configs['alignment_file'].format(virus=virus, subtype=subtype, gene=parent_gene)\n",
    "        meta_file = configs['meta_file'].format(virus=virus, subtype=subtype, gene=parent_gene)\n",
    "        #some are comma-separated, some are tab-separated\n",
    "        metafile_sep = configs['metafile_sep']\n",
    "    else:\n",
    "        reference_file = configs['reference_file'].format(virus=virus, subtype=subtype, gene=gene)\n",
    "        alignment_file = configs['alignment_file'].format(virus=virus, subtype=subtype, gene=gene)\n",
    "        meta_file = configs['meta_file'].format(virus=virus, subtype=subtype, gene=gene)\n",
    "        metafile_sep = configs['metafile_sep']\n",
    "    \n",
    "    #Find gene location, if domain is sub-genic or reference file contains multiple genes\n",
    "    gene_location = False\n",
    "    #If domain is sub-genic, fetch its position (within genome or parent gene) from config file\n",
    "\n",
    "\n",
    "    if 'specify_location' in configs[standard_gene].keys():\n",
    "        if subtype==None:\n",
    "            gene_location_key = \"location\"\n",
    "        else:\n",
    "            gene_location_key = \"location_\"+str(subtype)\n",
    "            \n",
    "        gene_location_list = ast.literal_eval(configs[standard_gene]['specify_location'][gene_location_key])\n",
    "        #Need to deal with domains the are not contiguous\n",
    "        if len(gene_location_list)==1:\n",
    "            gene_location = SeqFeature(FeatureLocation(gene_location_list[0][0], gene_location_list[0][1]))\n",
    "        else:\n",
    "            compound_locations = []\n",
    "            for location in gene_location_list:\n",
    "                compound_locations.append(FeatureLocation(location[0], location[1]))\n",
    "            gene_location = CompoundLocation(compound_locations)\n",
    "\n",
    "    #Find gene location from reference files\n",
    "    else:\n",
    "        for seq_record in SeqIO.parse(reference_file, \"genbank\"):\n",
    "            for feature in seq_record.features:\n",
    "                if feature.type == 'CDS':\n",
    "                    if 'gene' in feature.qualifiers.keys():\n",
    "                        if feature.qualifiers['gene'][0].lower() == gene.lower():\n",
    "                            gene_location = feature.location\n",
    "                    elif feature.qualifiers['product'][0].lower() == gene.lower():\n",
    "                        gene_location = feature.location                \n",
    "\n",
    "    #Subset data based on time windows\n",
    "    meta = pd.read_csv(meta_file, sep = metafile_sep)\n",
    "    meta.drop(meta[meta['date']=='?'].index, inplace=True)\n",
    "    meta.dropna(subset=['date'], inplace=True)\n",
    "    meta['year'] = meta['date'].str[:4].astype('int')\n",
    "    if year_max:\n",
    "        meta.drop(meta[meta['year']>year_max].index, inplace=True)\n",
    "    if year_min:\n",
    "        meta.drop(meta[meta['year']<year_min].index, inplace=True)\n",
    "    \n",
    "    date_range = meta['year'].max() - meta['year'].min()\n",
    "    #Remove egg- and cell-passaged strains\n",
    "    meta.drop(meta[meta['strain'].str[-4:]=='-egg'].index, inplace=True)\n",
    "    meta.drop(meta[meta['strain'].str[-5:]=='-cell'].index, inplace=True)\n",
    "    \n",
    "    #Limit meta data to only strains in alignment file\n",
    "    aligned_isolates = []\n",
    "    with open(alignment_file, \"r\") as aligned_handle:\n",
    "        for isolate in SeqIO.parse(aligned_handle, \"fasta\"):\n",
    "            aligned_isolates.append(isolate.id)\n",
    "    aligned_isolates_df = pd.DataFrame(aligned_isolates, columns=['strain'])\n",
    "    meta = meta.merge(aligned_isolates_df, on='strain', how='inner')\n",
    "    \n",
    "    \n",
    "    #Group viruses by time windows\n",
    "    virus_time_subset = {}\n",
    "    if window == 'all':\n",
    "        years = str(meta['year'].min()) + '-' + str(meta['year'].max())\n",
    "        virus_time_subset[years] = meta['strain'].tolist()\n",
    "    else:\n",
    "        date_window_start = meta['year'].min()\n",
    "        date_window_end = meta['year'].min() + window\n",
    "        while date_window_end <= meta['year'].max():\n",
    "            years = str(date_window_start) + '-' + str(date_window_end)\n",
    "            strains = meta[(meta['year']>=date_window_start) & (meta['year']<date_window_end)]['strain'].tolist()\n",
    "            virus_time_subset[years] = strains\n",
    "            \n",
    "            \n",
    "            #sliding window\n",
    "            date_window_end += 1\n",
    "            date_window_start += 1 \n",
    "    \n",
    "\n",
    "    #Only use time points with enough data:\n",
    "    virus_time_subset = {k:v for k,v in virus_time_subset.items() if len(v)>=min_seqs}\n",
    "\n",
    "    year_windows = []\n",
    "    seqs_in_window = []\n",
    "    \n",
    "    #Find outgroup sequence from strains at first time point(to make consensus from)\n",
    "    first_window = True\n",
    "    first_window_strains = []\n",
    "    first_window_sequences = []\n",
    "    \n",
    "    alignment_time_subset = {}\n",
    "\n",
    "    \n",
    "    for years, subset_viruses in virus_time_subset.items():\n",
    "\n",
    "        year_windows.append(years)\n",
    "        seqs_in_window.append(len(subset_viruses))\n",
    "        alignment_time_subset[years] = []\n",
    "\n",
    "        #make consensus sequence at first time point\n",
    "        if first_window == True:\n",
    "            first_window_strains+=subset_viruses\n",
    "            first_window = False\n",
    "        \n",
    "\n",
    "        with open(alignment_file, \"r\") as aligned_handle:\n",
    "            for isolate in SeqIO.parse(aligned_handle, \"fasta\"):\n",
    "                if isolate.id in first_window_strains:\n",
    "                    if gene_location:\n",
    "                        gene_record = SeqRecord(seq = gene_location.extract(isolate.seq), \n",
    "                                                id = isolate.id, description = gene)\n",
    "                    else:\n",
    "                        gene_record = SeqRecord(seq = isolate.seq, \n",
    "                                                id = isolate.id, description = gene)\n",
    "                    first_window_sequences.append(gene_record)\n",
    "                if isolate.id in subset_viruses:\n",
    "                    if gene_location:\n",
    "                        alignment_time_subset[years].append(gene_location.extract(isolate.seq))\n",
    "                    else:\n",
    "                        alignment_time_subset[years].append(isolate.seq)\n",
    "\n",
    "    first_window_alignment = MultipleSeqAlignment(first_window_sequences)\n",
    "    outgroup_seq = AlignInfo.SummaryInfo(first_window_alignment).gap_consensus(ambiguous ='N')\n",
    "    \n",
    "    has_dup = find_duplication(outgroup_seq)\n",
    "    \n",
    "    #if virus has duplication, want to run Bhatt on entire alignment excluding dup, \n",
    "    #and then separately on the duplicated sequence to look at evolution occurring on top of it\n",
    "    \n",
    "    if has_dup:\n",
    "        outgroup_seq, outgroup_seq_aa, alignment_time_subset, year_windows, seqs_in_window = adjust_for_duplications(outgroup_seq, alignment_time_subset, \n",
    "                                                                                       alignment_to_return, \n",
    "                                                                                       year_windows, seqs_in_window)\n",
    "    else:\n",
    "        outgroup_seq_aa = outgroup_seq.translate()\n",
    "        \n",
    "    return alignment_time_subset, outgroup_seq, outgroup_seq_aa, year_windows, seqs_in_window \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplication(outgroup_seq):\n",
    "    \"\"\"\n",
    "    Duplication events (or any insertions) will be signified in the outgroup sequence \n",
    "    by a series of consecutive --- placeholders. Find if there is a duplication in this \n",
    "    evolution of this virus.\n",
    "    \"\"\"\n",
    "    has_dup = False\n",
    "    outgroup_seq_str = str(outgroup_seq)\n",
    "    #if there are ---s in the outgroup_seq, find where they are\n",
    "    if re.search(\"-+\", outgroup_seq_str):\n",
    "        dup_start, dup_end = [(x.start(),x.end()) for x in re.finditer(r'(\\-)\\1\\1', outgroup_seq_str)][0]\n",
    "        has_dup=True\n",
    "        \n",
    "    return has_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_duplications(outgroup_seq, alignment_time_subset, alignment_to_return, year_windows, seqs_in_window):\n",
    "    \"\"\"\n",
    "    Find the position and length of the duplication.\n",
    "    Remove the duplicated region from the outgroup sequence and the every sequence in the alignment.\n",
    "    Evolution on the duplicated region will be considered separately because the outgroup consensus \n",
    "    for this region needs to done from the first timepoint where there are sequences with the duplication\n",
    "    \"\"\"\n",
    "\n",
    "    outgroup_seq_str = str(outgroup_seq)\n",
    "    #find where the duplication is by locating ---s in the outgroup_seq\n",
    "    if re.search(\"-+\", outgroup_seq_str):\n",
    "        dup_start, dup_end = [(x.start(),x.end()) for x in re.finditer(r'(\\-)+', outgroup_seq_str)][0]\n",
    "\n",
    "\n",
    "    outgroup_wo_dup = Seq(outgroup_seq_str[:dup_start]+outgroup_seq_str[dup_end:])\n",
    "    outgroup_wo_dup_aa = outgroup_wo_dup.translate()\n",
    "\n",
    "    # remove the duplicated portion from the main alignment\n",
    "    alignment_time_subset_wo_dup = {}\n",
    "    for dates, strain_seqs in alignment_time_subset.items():\n",
    "        strain_seqs_wo_dup = [Seq(str(x)[:dup_start]+str(x)[dup_end:]) for x in strain_seqs]\n",
    "        alignment_time_subset_wo_dup[dates] = strain_seqs_wo_dup\n",
    "    \n",
    "    # also write an alignment of just the duplicated seq\n",
    "    alignment_time_subset_duplicated_seq = {}\n",
    "    for dates, strain_seqs in alignment_time_subset.items():\n",
    "        strain_seqs_dup_only = [Seq(str(x)[dup_start:dup_end]) for x in strain_seqs]\n",
    "        alignment_time_subset_duplicated_seq[dates] = strain_seqs_dup_only\n",
    "    \n",
    "    dup_len = int(dup_end)-int(dup_start)\n",
    "    \n",
    "    #find the first time point where duplication exists\n",
    "    first_duplication_timepoint = False\n",
    "    #truncate the alignment to only time points after duplication has occured \n",
    "    alignment_time_subset_duplication = {}\n",
    "    for dates, dup_seqs in alignment_time_subset_duplicated_seq.items():\n",
    "        if first_duplication_timepoint == True:\n",
    "            seqs_with_dup = [x for x in dup_seqs if str(x)!='-'*dup_len]\n",
    "            alignment_time_subset_duplication[dates] = seqs_with_dup\n",
    "            \n",
    "        elif first_duplication_timepoint == False:\n",
    "            seqs_with_dup = [x for x in dup_seqs if str(x)!='-'*dup_len]\n",
    "            if len(seqs_with_dup)!=0:\n",
    "                first_duplication_window_seqs = []\n",
    "                for x in seqs_with_dup:\n",
    "                    first_duplication_window_seqs.append(SeqRecord(seq=x))\n",
    "                first_duplication_timepoint = True\n",
    "            \n",
    "    first_duplication_window_alignment = MultipleSeqAlignment(first_duplication_window_seqs)\n",
    "    outgroup_dup = AlignInfo.SummaryInfo(first_duplication_window_alignment).gap_consensus(ambiguous ='N')\n",
    "    outgroup_dup_aa = outgroup_dup.translate()\n",
    "    \n",
    "    year_windows_dup = [k for k,v in alignment_time_subset_duplication.items()]\n",
    "    seqs_in_window_dup = [len(y) for x, y in alignment_time_subset_duplication.items()]\n",
    "    \n",
    "    # don't touch year_windows, seqs_in_window if this is main alignment\n",
    "    # if it is the duplication alignment, need to truncate these accordingly\n",
    "    \n",
    "    if alignment_to_return == 'main':\n",
    "        return outgroup_wo_dup, outgroup_wo_dup_aa, alignment_time_subset_wo_dup, year_windows, seqs_in_window\n",
    "    \n",
    "    elif alignment_to_return == 'duplication':\n",
    "        return outgroup_dup, outgroup_dup_aa, alignment_time_subset_duplication, year_windows_dup, seqs_in_window_dup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each time point, create sample alignment of same size as emperical alignment\n",
    "def bootstrap_alignment(bootstrap_codon_order, sequences):\n",
    "    \n",
    "    bootstrap_alignment_seqs = []\n",
    "    for virus_seq in sequences:\n",
    "        virus_seq_str = str(virus_seq)\n",
    "        virus_codons = [virus_seq_str[i:i+3] for i in range(0, len(virus_seq_str), 3)] \n",
    "        bootstrap_virus = ''.join([virus_codons[x] for x in bootstrap_codon_order])\n",
    "        bootstrap_alignment_seqs.append(bootstrap_virus)\n",
    "    \n",
    "    return bootstrap_alignment_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample codons from emperical ancestral sequence with replacement\n",
    "def bootstrap_ancestral(outgroup_seq):\n",
    "    outgroup_seq_str = str(outgroup_seq)\n",
    "    #sample codons with replacement\n",
    "    ancestral_codons = [outgroup_seq_str[i:i+3] for i in range(0, len(outgroup_seq_str), 3)] \n",
    "    bootstrap_codon_order = random.choices(range(len(ancestral_codons)), k=len(ancestral_codons))\n",
    "    bootstrap_ancestral_seq = ''.join([ancestral_codons[x] for x in bootstrap_codon_order])\n",
    "    bootstrap_ancestral_seq = Seq(bootstrap_ancestral_seq)\n",
    "    return bootstrap_ancestral_seq, bootstrap_codon_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bootstrap_dataset(outgroup_seq, alignment_time_subset):\n",
    "            \n",
    "    bootstrap_ancestral_seq, bootstrap_codon_order = bootstrap_ancestral(outgroup_seq)\n",
    "    bootstrap_ancestral_seq_aa = bootstrap_ancestral_seq.translate()\n",
    "    \n",
    "    bootstrap_alignment_seqs = {}\n",
    "    for years, sequences in alignment_time_subset.items():\n",
    "        bootstrap_sequences = bootstrap_alignment(bootstrap_codon_order, sequences)\n",
    "        bootstrap_alignment_seqs[years] = bootstrap_sequences\n",
    "\n",
    "        \n",
    "    return bootstrap_ancestral_seq, bootstrap_ancestral_seq_aa, bootstrap_alignment_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_site_stats(alignment_sequences, outgroup_seq, outgroup_aa_seq, midfreq_high, midfreq_low):\n",
    "    \n",
    "    #Find percent polymorphism at each site\n",
    "    #Also determine whether polymorphism is silent or replacement  \n",
    "    \n",
    "\n",
    "    #initiate lists to record all time windows\n",
    "    frequency_bins = []\n",
    "    fixation_scores = []\n",
    "    polymorphism_scores = []\n",
    "    replacement_scores = []\n",
    "    silent_scores = []    \n",
    "        \n",
    "\n",
    "    for years, alignment_seqs in alignment_sequences.items():\n",
    "  \n",
    "        #calculate stats for each window separately\n",
    "        freq_bins, replacement_score, ingroup_bases = walk_through_sites(outgroup_seq, outgroup_aa_seq, \n",
    "                                                                         alignment_seqs,\n",
    "                                                                         midfreq_high, midfreq_low)\n",
    "        Fi_all, Pi_all = assign_fi_pi(outgroup_seq, ingroup_bases)\n",
    "        silent_score = 1-replacement_score\n",
    "\n",
    "        frequency_bins.append(freq_bins)\n",
    "        fixation_scores.append(Fi_all)\n",
    "        polymorphism_scores.append(Pi_all)\n",
    "        replacement_scores.append(replacement_score)\n",
    "        silent_scores.append(silent_score)\n",
    "            \n",
    "            \n",
    "            \n",
    "    return frequency_bins, fixation_scores, polymorphism_scores, replacement_scores, silent_scores\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M=rm/sm \n",
    "#not expected to vary through time provided that long-term effective population sizes remain sufficiently large\n",
    "#For each gene, calculate M by combining site count among time points\n",
    "\n",
    "def calc_m_ratio(virus, subtype, gene, window, min_seqs, midfreq_high, midfreq_low, bootstrap, year_max, year_min):\n",
    "\n",
    "    if '_duplication' in gene:\n",
    "        gene = str(gene[0])\n",
    "\n",
    "    configs = readin_virus_config(virus)\n",
    "    nonantigenic_gene = configs['membrane_fusion']['virus_gene']\n",
    "\n",
    "    \n",
    "    if standardize_gene_name(virus, gene) =='ha_protein' or standardize_gene_name(virus, gene) =='receptor_binding':\n",
    "        (alignment_time_subset, \n",
    "         outgroup_seq, outgroup_aa_seq, \n",
    "         year_windows, seqs_in_window) = subset_viruses_nextstrain_build(virus, subtype, nonantigenic_gene, 'all', \n",
    "                                                        min_seqs, year_max, year_min)\n",
    "        if bootstrap:\n",
    "            (bootstrap_ancestral_seq, bootstrap_ancestral_seq_aa,\n",
    "             bootstrap_alignment_seqs) = make_bootstrap_dataset(outgroup_seq, alignment_time_subset)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        (alignment_time_subset, \n",
    "         outgroup_seq, outgroup_aa_seq, \n",
    "         year_windows, seqs_in_window) = subset_viruses_nextstrain_build(virus, subtype, gene, 'all', \n",
    "                                                        min_seqs, year_max, year_min)\n",
    "        if bootstrap:\n",
    "            (bootstrap_ancestral_seq, bootstrap_ancestral_seq_aa,\n",
    "             bootstrap_alignment_seqs) = make_bootstrap_dataset(outgroup_seq, alignment_time_subset)\n",
    "    \n",
    "    if bootstrap:\n",
    "            (frequency_bins, \n",
    "             fixation_scores, polymorphism_scores, \n",
    "             replacement_scores, silent_scores) = calc_site_stats(bootstrap_alignment_seqs, \n",
    "                                                                  bootstrap_ancestral_seq, bootstrap_ancestral_seq_aa, \n",
    "                                                                  midfreq_high, midfreq_low)\n",
    "    else:\n",
    "        (frequency_bins, \n",
    "         fixation_scores, polymorphism_scores, \n",
    "         replacement_scores, silent_scores) = calc_site_stats(alignment_time_subset, \n",
    "                                                              outgroup_seq, outgroup_aa_seq, midfreq_high, midfreq_low)\n",
    "        \n",
    "    \n",
    "    sm = 0\n",
    "    rm = 0\n",
    "    \n",
    "    for site in range(len(frequency_bins[0])):\n",
    "        freq_bin = frequency_bins[0][site]\n",
    "        if freq_bin == 'm':\n",
    "            sm+= (polymorphism_scores[0][site]*silent_scores[0][site])\n",
    "            rm+= (polymorphism_scores[0][site]*replacement_scores[0][site])\n",
    "    \n",
    "    if sm ==0:\n",
    "        sm = 0.00000000000000001\n",
    "    m_ratio = rm/sm\n",
    "    \n",
    "    return m_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bhatt_estimators(gene, outgroup_seq, frequency_bins, year_windows, fixation_scores, polymorphism_scores, replacement_scores, silent_scores, m_ratio):\n",
    "\n",
    "    \n",
    "    #Initiate lists to store a values\n",
    "    window_midpoint = []\n",
    "    adaptive_substitutions = []\n",
    "    \n",
    "    #for each window, calculate bhatt estimators \n",
    "    for years_window in range(len(frequency_bins)):\n",
    "        window_start = int(year_windows[years_window][0:4])\n",
    "        window_end = int(year_windows[years_window][-4:])\n",
    "        window_midpoint.append((window_start + window_end)/2)\n",
    "\n",
    "        sf = 0\n",
    "        rf = 0\n",
    "        sh = 0\n",
    "        rh = 0\n",
    "        sm = 0\n",
    "        rm = 0\n",
    "        sl = 0\n",
    "        rl = 0\n",
    "\n",
    "        #calculate number of sites in different catagories (defined by polymorphic freq at that site)\n",
    "        window_freq_bins = frequency_bins[years_window]\n",
    "        for site in range(len(window_freq_bins)):\n",
    "            freq_bin = window_freq_bins[site]\n",
    "            #ignore sites with no polymorphisms?\n",
    "            if freq_bin!='nan':\n",
    "                if freq_bin == 'f':\n",
    "                    sf+= (fixation_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                    rf+= (fixation_scores[years_window][site]*replacement_scores[years_window][site])\n",
    "                elif freq_bin == 'h':\n",
    "                    sh+= (polymorphism_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                    rh+= (polymorphism_scores[years_window][site]*replacement_scores[years_window][site])\n",
    "                elif freq_bin == 'm':\n",
    "                    sm+= (polymorphism_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                    rm+= (polymorphism_scores[years_window][site]*replacement_scores[years_window][site])\n",
    "                elif freq_bin == 'l':\n",
    "                    sl+= (polymorphism_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                    rl+= (polymorphism_scores[years_window][site]*replacement_scores[years_window][site])       \n",
    "        \n",
    "\n",
    "#         print(year_windows[years_window])\n",
    "#         print(sf, rf, sh, rh, sm, rm, sl, rl)  \n",
    "\n",
    "        #Calculate equation 1: number of nonneutral sites\n",
    "        al = rl - sl*m_ratio\n",
    "        ah = rh - sh*m_ratio\n",
    "        af = rf - sf*m_ratio\n",
    "        \n",
    "        #set negative a values to zero\n",
    "        if al < 0:\n",
    "            al = 0\n",
    "        if ah < 0:\n",
    "            ah = 0\n",
    "        if af < 0:\n",
    "            af = 0\n",
    "\n",
    "#             print(al, ah, af)\n",
    "\n",
    "        #Calculate the number and proportion of all fixed or high-freq sites that have undergone adaptive change\n",
    "        number_adaptive_substitutions = af + ah\n",
    "        adaptive_substitutions.append(number_adaptive_substitutions)\n",
    "#         proportion_adaptive_sites = (af + ah)/(rf +rh)\n",
    "\n",
    "    \n",
    "    gene_length = len(outgroup_seq)\n",
    "    adaptive_substitutions_per_codon = [x/gene_length for x in adaptive_substitutions]\n",
    "    \n",
    "    if len(window_midpoint)!=0:\n",
    "        rate_of_adaptation, intercept, r_value, p_value, std_err = stats.linregress(window_midpoint, adaptive_substitutions_per_codon)\n",
    "    else:\n",
    "        rate_of_adaptation = 0\n",
    "            \n",
    "    return window_midpoint, adaptive_substitutions, adaptive_substitutions_per_codon, rate_of_adaptation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bhatt_a(virus, subtype, gene, window, min_seqs, midfreq_high, midfreq_low, bootstrap, year_max, year_min):\n",
    "    #Get virus subset\n",
    "\n",
    "    (alignment_time_subset, \n",
    "     outgroup_seq, outgroup_aa_seq, year_windows, seqs_in_window) = subset_viruses_nextstrain_build(virus, subtype, gene, \n",
    "                                                                                   window, min_seqs, \n",
    "                                                                                   year_max, year_min)\n",
    "#     print(alignment_time_subset, [len(alignment_time_subset[x]) for x in alignment_time_subset.keys()], seqs_in_window)\n",
    "    \n",
    "    #calculate m ratio\n",
    "    m_ratio = calc_m_ratio(virus, subtype, gene, window, \n",
    "                           min_seqs, midfreq_high, midfreq_low, False, \n",
    "                           year_max, year_min)\n",
    "    \n",
    "    #Calculate frequencies for emperical data\n",
    "    (frequency_bins, \n",
    "     fixation_scores, polymorphism_scores, \n",
    "     replacement_scores, silent_scores) = calc_site_stats(alignment_time_subset, outgroup_seq, \n",
    "                                                          outgroup_aa_seq, midfreq_high, midfreq_low)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #calculate bhatt estimators\n",
    "    (window_midpoint, adaptive_substitutions, \n",
    "     adaptive_substitutions_per_codon, rate_of_adaptation) = bhatt_estimators(gene, outgroup_seq, \n",
    "                                                                              frequency_bins, year_windows, \n",
    "                                                                              fixation_scores, polymorphism_scores, \n",
    "                                                                              replacement_scores, silent_scores, m_ratio)\n",
    "    \n",
    "    \n",
    "    n_bootstraps = 100\n",
    "    bootstrap_count = 0\n",
    "    \n",
    "    bootstrap_adaptive_substitutions = []\n",
    "    bootstrap_adaptive_substitutions_per_codon = []\n",
    "    bootstrap_rate_of_adaptation = []\n",
    "    if bootstrap:\n",
    "        while bootstrap_count < n_bootstraps:\n",
    "            bootstrap_count+=1\n",
    "            #Get bootstrapped ancestral seq and alignment\n",
    "            (bootstrap_ancestral_seq, bootstrap_ancestral_seq_aa,\n",
    "             bootstrap_alignment_seqs) = make_bootstrap_dataset(outgroup_seq, alignment_time_subset)\n",
    "\n",
    "\n",
    "            #Calculate frequencies for bootstrap data\n",
    "            (bootstrap_frequency_bins, \n",
    "             bootstrap_fixation_scores, bootstrap_polymorphism_scores, \n",
    "             bootstrap_replacement_scores, bootstrap_silent_scores) = calc_site_stats(bootstrap_alignment_seqs, \n",
    "                                                                                      bootstrap_ancestral_seq, \n",
    "                                                                                      bootstrap_ancestral_seq_aa, \n",
    "                                                                                      midfreq_high, midfreq_low)\n",
    "            #Calculate m ratio\n",
    "            bootstrap_m_ratio = calc_m_ratio(virus, subtype, gene, window, \n",
    "                                             min_seqs, midfreq_high, midfreq_low, True,  \n",
    "                                             year_max, year_min)\n",
    "\n",
    "            #calculate bhatt estimators\n",
    "            (bs_window_midpoint, bs_adaptive_substitutions, \n",
    "             bs_adaptive_substitutions_per_codon, \n",
    "             bs_rate_of_adaptation) = bhatt_estimators(gene, bootstrap_ancestral_seq, \n",
    "                                                              bootstrap_frequency_bins, year_windows, \n",
    "                                                              bootstrap_fixation_scores, \n",
    "                                                              bootstrap_polymorphism_scores, \n",
    "                                                              bootstrap_replacement_scores, bootstrap_silent_scores, \n",
    "                                                              bootstrap_m_ratio)\n",
    "            #add these bootstrap values to list\n",
    "            bootstrap_adaptive_substitutions.append(bs_adaptive_substitutions)\n",
    "            bootstrap_adaptive_substitutions_per_codon.append(bs_adaptive_substitutions_per_codon)\n",
    "            bootstrap_rate_of_adaptation.append(bs_rate_of_adaptation)\n",
    "    \n",
    "    if bootstrap:\n",
    "        return window_midpoint, adaptive_substitutions, adaptive_substitutions_per_codon, rate_of_adaptation, bootstrap_adaptive_substitutions, bootstrap_adaptive_substitutions_per_codon, bootstrap_rate_of_adaptation\n",
    "\n",
    "    else:\n",
    "        return window_midpoint, adaptive_substitutions, adaptive_substitutions_per_codon, rate_of_adaptation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_gene_name_reverse(virus, gene):\n",
    "    \n",
    "    configs = readin_virus_config(virus)\n",
    "    \n",
    "    genes = ['polymerase', 'receptor_binding', 'membrane_fusion']\n",
    "    gene_names = {x: configs[x]['virus_gene'] for x in genes}\n",
    "    \n",
    "    return gene_names[gene]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_gene_name(virus, gene):\n",
    "    configs = readin_virus_config(virus)\n",
    "    \n",
    "    genes = ['polymerase', 'receptor_binding', 'membrane_fusion']\n",
    "    gene_names = {configs[x]['virus_gene']:x for x in genes}\n",
    "    \n",
    "    return gene_names[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_to_plot(virus, subtype, gene, bootstrap, window, min_seqs, midfreq_high, midfreq_low, year_max, year_min):\n",
    "\n",
    "    \n",
    "    data_to_plot = []\n",
    "    \n",
    "    if subtype==None:\n",
    "        virus_subtype = virus\n",
    "        virus_and_subtype = virus\n",
    "    else:\n",
    "        virus_subtype = subtype\n",
    "        virus_and_subtype = virus+'_'+subtype\n",
    "    \n",
    "    if bootstrap:\n",
    "        save_json_name = 'bhatt_results_nextstrain/'+str(virus_and_subtype)+'_'+str(gene)+'_bhatt_analysis_bootstrapped.json'\n",
    "        if path.exists(save_json_name):\n",
    "            with open(save_json_name) as json_handle:\n",
    "                json_dict = json.load(json_handle)\n",
    "                (window_midpoint, adaptive_substitutions, \n",
    "                 adaptive_substitutions_per_codon, \n",
    "                 rate_of_adaptation, bootstrap_adaptive_substitutions, \n",
    "                 bootstrap_adaptive_substitutions_per_codon, \n",
    "                 bootstrap_rate_of_adaptation) = (json_dict['window_midpoint'], \n",
    "                                                  json_dict['adaptive_substitutions'], \n",
    "                                                  json_dict['adaptive_substitutions_per_codon'], \n",
    "                                                  json_dict['rate_of_adaptation'], \n",
    "                                                  json_dict['bootstrap_adaptive_substitutions'], \n",
    "                                                  json_dict['bootstrap_adaptive_substitutions_per_codon'], \n",
    "                                                  json_dict['bootstrap_rate_of_adaptation'])\n",
    "\n",
    "        else:\n",
    "\n",
    "            (window_midpoint, adaptive_substitutions, \n",
    "             adaptive_substitutions_per_codon, \n",
    "             rate_of_adaptation, bootstrap_adaptive_substitutions, \n",
    "             bootstrap_adaptive_substitutions_per_codon, \n",
    "             bootstrap_rate_of_adaptation) = calc_bhatt_a(virus, subtype, gene, window, \n",
    "                                                          min_seqs, midfreq_high, \n",
    "                                                          midfreq_low, bootstrap, year_max, year_min)\n",
    "\n",
    "            save_json = {'virus': virus, 'subtype':subtype, 'gene': gene, 'window':window, 'min_seqs': min_seqs, \n",
    "                         'midfreq_high': midfreq_high, 'midfreq_low': midfreq_low,\n",
    "                         'window_midpoint':window_midpoint, 'adaptive_substitutions':adaptive_substitutions, \n",
    "                         'adaptive_substitutions_per_codon':adaptive_substitutions_per_codon, 'rate_of_adaptation': rate_of_adaptation,\n",
    "                         'bootstrap_adaptive_substitutions': bootstrap_adaptive_substitutions, \n",
    "                         'bootstrap_adaptive_substitutions_per_codon': bootstrap_adaptive_substitutions_per_codon, \n",
    "                         'bootstrap_rate_of_adaptation':bootstrap_rate_of_adaptation}\n",
    "            with open(save_json_name, 'w') as outfile:\n",
    "                json.dump(save_json, outfile)\n",
    "\n",
    "        slope_sci = rate_of_adaptation * (10**3)\n",
    "        bs_slope_sci = [x * (10**3) for x in bootstrap_rate_of_adaptation]\n",
    "        lower_95ci = np.percentile(sorted(bs_slope_sci), 2.5)\n",
    "        upper_95ci = np.percentile(sorted(bs_slope_sci), 97.5)\n",
    "\n",
    "        data_to_plot.append({'virus': virus, 'subtype': subtype, 'virus_and_subtype': virus_and_subtype, \n",
    "                             'gene': gene,\n",
    "                             'adaptive_subs_per_codon_per_year': slope_sci, \n",
    "                             'lower_95ci': lower_95ci, 'upper_95ci': upper_95ci, \n",
    "                             'ci': [lower_95ci, upper_95ci]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        save_json_name = 'bhatt_results_nextstrain/'+str(virus_and_subtype)+'_'+str(gene)+'_bhatt_analysis.json'\n",
    "        if path.exists(save_json_name):\n",
    "            with open(save_json_name) as json_handle:\n",
    "                json_dict = json.load(json_handle)\n",
    "                (window_midpoint, adaptive_substitutions, \n",
    "                 adaptive_substitutions_per_codon, \n",
    "                 rate_of_adaptation) = (json_dict['window_midpoint'], \n",
    "                                        json_dict['adaptive_substitutions'], \n",
    "                                        json_dict['adaptive_substitutions_per_codon'], \n",
    "                                        json_dict['rate_of_adaptation'])\n",
    "\n",
    "\n",
    "        else:\n",
    "            (window_midpoint, adaptive_substitutions, \n",
    "             adaptive_substitutions_per_codon, \n",
    "             rate_of_adaptation) = calc_bhatt_a(virus, subtype, gene, window, min_seqs, \n",
    "                                                midfreq_high, midfreq_low, \n",
    "                                                bootstrap, year_max, year_min)\n",
    "            \n",
    "\n",
    "            save_json = {'virus': virus, 'subtype':subtype, 'gene': gene, 'window':window, 'min_seqs': min_seqs, \n",
    "                         'midfreq_high': midfreq_high, 'midfreq_low': midfreq_low,\n",
    "                         'window_midpoint':window_midpoint, 'adaptive_substitutions':adaptive_substitutions, \n",
    "                         'adaptive_substitutions_per_codon':adaptive_substitutions_per_codon, \n",
    "                         'rate_of_adaptation': rate_of_adaptation}\n",
    "            with open(save_json_name, 'w') as outfile:\n",
    "                json.dump(save_json, outfile)\n",
    "\n",
    "        slope_sci = rate_of_adaptation * (10**3)\n",
    "        data_to_plot.append({'virus': virus, 'subtype': subtype, 'virus_and_subtype':virus_and_subtype, \n",
    "                             'gene': gene,\n",
    "                             'adaptive_subs_per_codon_per_year': slope_sci})\n",
    "    \n",
    "\n",
    "    return data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated as slope of adaptive subs per codon\n",
    "def compare_rsv_duplication_rate(standard_genes=['polymerase', 'receptor_binding', 'membrane_fusion'], \n",
    "                                  window=3, min_seqs=2, bootstrap=False, \n",
    "                                  midfreq_high=0.75, midfreq_low=0.15, year_max=None, year_min=None, filename=None):\n",
    "    \n",
    "\n",
    "    virus = 'rsv'\n",
    "    data_to_plot = []\n",
    "    color_map = {}\n",
    "\n",
    "    \n",
    "        \n",
    "    configs = readin_virus_config(virus)\n",
    "#     genes = [standardize_gene_name_reverse(virus, x) for x in standard_genes]\n",
    "    genes= ['L', 'G','G_duplication', 'F']\n",
    "\n",
    "    subtypes = configs['subtypes']\n",
    "    for subtype in subtypes:\n",
    "        virus_and_sub = virus+'_'+subtype\n",
    "        color_map[virus_and_sub] = configs['color'][subtype]\n",
    "        for gene in genes:\n",
    "            data_to_plot+=get_data_to_plot(virus, subtype, gene, bootstrap, window, \n",
    "                                                 min_seqs, midfreq_high, midfreq_low, year_max, year_min)\n",
    "                    \n",
    "\n",
    "\n",
    "    df_to_plot = pd.DataFrame(data_to_plot)\n",
    "    \n",
    "    viruses_and_subtypes = list(df_to_plot['virus_and_subtype'].unique())\n",
    "    \n",
    "    x_coords = {}\n",
    "    \n",
    "    all_x_ticks = []\n",
    "    last_coord = 0.0\n",
    "    spacing = {**{x:0.25 for x in range(1,8)}, **{y:0.4 for y in range(8,12)}, **{z:0.7 for z in range(12,20)}}\n",
    "    spacing_genes = {**{x:1.0 for x in range(1,8)}, **{y:1.8 for y in range(8,12)}, **{z:2.4 for z in range(12,20)}}\n",
    "    for gene in genes:\n",
    "        x_coords[gene] = {}\n",
    "        for virus_subtype in viruses_and_subtypes:\n",
    "            last_coord+=spacing[len(viruses_and_subtypes)]\n",
    "            x_coords[gene][virus_subtype] = last_coord\n",
    "            all_x_ticks.append(last_coord)\n",
    "        last_coord+=spacing_genes[len(viruses_and_subtypes)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    \n",
    "    x_labels = []\n",
    "    gene_ticks = []\n",
    "    \n",
    "    \n",
    "    for gene in genes:\n",
    "        gene_coords = list(x_coords[gene].values())\n",
    "        gene_ticks.append(sum(gene_coords)/len(gene_coords))\n",
    "        x_labels.append(gene)\n",
    "        for virus_subtype in viruses_and_subtypes:\n",
    "            x = x_coords[gene][virus_subtype]\n",
    "            df_row = df_to_plot[(df_to_plot['gene']==gene)&(df_to_plot['virus_and_subtype']==virus_subtype)]\n",
    "            y = float(df_row['adaptive_subs_per_codon_per_year'])\n",
    "            if bootstrap:\n",
    "                err_lower = float(df_row['lower_95ci'])\n",
    "                err_upper = float(df_row['upper_95ci'])\n",
    "                ax.vlines( x, err_lower, err_upper, color='black')\n",
    "            ax.plot(x, y, 'o', ms=12, color=color_map[virus_subtype])\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    plt.xticks(gene_ticks, x_labels)\n",
    "\n",
    "    legend_markers = []\n",
    "    used_families = []\n",
    "\n",
    "    for virus_subtype in viruses_and_subtypes:\n",
    "        legend_markers.append(mlines.Line2D([0], [0], color='w', markerfacecolor=color_map[virus_subtype], marker='o',\n",
    "                                            markersize=12, label=virus_subtype))\n",
    "    plt.legend(handles=legend_markers, loc='upper right')\n",
    "    \n",
    "    plt.ylabel('adaptive subs per codon per year (x10^-3)')\n",
    "#     plt.xlabel('gene')\n",
    "    \n",
    "    # remove box around plot\n",
    "    sns.despine(left=False, bottom=False)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if filename:\n",
    "        fig.savefig(filename, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_rsv_duplication_rate(bootstrap= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
