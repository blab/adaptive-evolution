{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation, CompoundLocation\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Align import AlignInfo\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readin_virus_config(virus):\n",
    "    config_json = f'config/adaptive_evo_config_{virus}.json'\n",
    "    with open(config_json) as json_handle:\n",
    "        configs = json.load(json_handle)\n",
    "        \n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_alignment(virus, subtype, gene, location, window, min_seqs, year_max, year_min):\n",
    "    \"\"\"\n",
    "    Get the alignment file and subset it into time windows (defined by window)\n",
    "    Each window must have at least min_seqs in it\n",
    "    Find the outgroup_seq as the consensus sequence at the first time point\n",
    "    \"\"\"\n",
    "    \n",
    "    configs = readin_virus_config(virus)\n",
    "    \n",
    "    \n",
    "    alignment_file = configs['alignment_file'].format(virus=virus, subtype=subtype, gene=gene)\n",
    "    meta_file = configs['meta_file'].format(virus=virus, subtype=subtype, gene=gene)\n",
    "    #some are comma-separated, some are tab-separated\n",
    "    metafile_sep = configs['metafile_sep']\n",
    "    \n",
    "    \n",
    "    meta = pd.read_csv(meta_file, sep = metafile_sep)\n",
    "    meta.drop(meta[meta['date']=='?'].index, inplace=True)\n",
    "    meta.dropna(subset=['date'], inplace=True)\n",
    "    meta = meta[meta[\"date\"].str.contains(\"20XX\")==False]\n",
    "    meta['year'] = meta['date'].str[:4].astype('int')\n",
    "    if year_max:\n",
    "        meta.drop(meta[meta['year']>year_max].index, inplace=True)\n",
    "    if year_min:\n",
    "        meta.drop(meta[meta['year']<year_min].index, inplace=True)\n",
    "    \n",
    "    #Remove egg- and cell-passaged strains\n",
    "    meta.drop(meta[meta['strain'].str[-4:]=='-egg'].index, inplace=True)\n",
    "    meta.drop(meta[meta['strain'].str[-5:]=='-cell'].index, inplace=True)\n",
    "    \n",
    "    #Limit meta data to only strains in alignment file\n",
    "    aligned_isolates = []\n",
    "    with open(alignment_file, \"r\") as aligned_handle:\n",
    "        for isolate in SeqIO.parse(aligned_handle, \"fasta\"):\n",
    "            aligned_isolates.append(isolate.id)\n",
    "    aligned_isolates_df = pd.DataFrame(aligned_isolates, columns=['strain'])\n",
    "    meta = meta.merge(aligned_isolates_df, on='strain', how='inner')\n",
    "    \n",
    "    #Group viruses by time windows\n",
    "    virus_time_subset = {}\n",
    "    date_window_start = meta['year'].min()\n",
    "    date_window_end = meta['year'].min() + window\n",
    "    while date_window_end <= meta['year'].max():\n",
    "        years = str(date_window_start) + '-' + str(date_window_end)\n",
    "        strains = meta[(meta['year']>=date_window_start) & (meta['year']<date_window_end)]['strain'].tolist()\n",
    "        virus_time_subset[years] = strains\n",
    "\n",
    "\n",
    "        #sliding window\n",
    "        date_window_end += 1\n",
    "        date_window_start += 1 \n",
    "\n",
    "    #for location of sub-genic locus, change list-format to SeqFeature\n",
    "    locus_location = SeqFeature(FeatureLocation(location[0], location[1]))   \n",
    "    \n",
    "\n",
    "    #Only use time points with enough data:\n",
    "    virus_time_subset = {k:v for k,v in virus_time_subset.items() if len(v)>=min_seqs}\n",
    "\n",
    "    year_windows = []\n",
    "    seqs_in_window = []\n",
    "    \n",
    "    #Find outgroup sequence from strains at first time point(to make consensus from)\n",
    "    first_window = True\n",
    "    first_window_strains = []\n",
    "    first_window_sequences = []\n",
    "    \n",
    "    alignment_time_subset = {}\n",
    "\n",
    "    \n",
    "    for years, subset_viruses in virus_time_subset.items():\n",
    "\n",
    "        year_windows.append(years)\n",
    "        seqs_in_window.append(len(subset_viruses))\n",
    "        alignment_time_subset[years] = []\n",
    "\n",
    "        #make consensus sequence at first time point\n",
    "        if first_window == True:\n",
    "            first_window_strains+=subset_viruses\n",
    "            first_window = False\n",
    "        \n",
    "\n",
    "        with open(alignment_file, \"r\") as aligned_handle:\n",
    "            for isolate in SeqIO.parse(aligned_handle, \"fasta\"):\n",
    "                if isolate.id in first_window_strains:\n",
    "                    gene_record = SeqRecord(seq = locus_location.extract(isolate.seq), \n",
    "                                            id = isolate.id, description = gene)\n",
    "\n",
    "                    first_window_sequences.append(gene_record)\n",
    "\n",
    "                if isolate.id in subset_viruses:\n",
    "                    alignment_time_subset[years].append(locus_location.extract(isolate.seq))\n",
    "\n",
    "\n",
    "    first_window_alignment = MultipleSeqAlignment(first_window_sequences)\n",
    "    if virus=='rsv':\n",
    "        outgroup_seq = AlignInfo.SummaryInfo(first_window_alignment).gap_consensus(ambiguous ='N')\n",
    "    else:\n",
    "        outgroup_seq = AlignInfo.SummaryInfo(first_window_alignment).dumb_consensus(ambiguous ='N')\n",
    "        \n",
    "    has_dup = find_duplication(outgroup_seq)\n",
    "    \n",
    "    #if virus has duplication, want to run Bhatt on entire alignment excluding dup, \n",
    "    #and then separately on the duplicated sequence to look at evolution occurring on top of it    \n",
    "    if has_dup:\n",
    "        outgroup_seq, outgroup_seq_aa, alignment_time_subset = adjust_for_duplications(outgroup_seq, alignment_time_subset)\n",
    "    else:\n",
    "        outgroup_seq_aa = outgroup_seq.translate()\n",
    "        \n",
    "        \n",
    "    return virus_time_subset, alignment_time_subset, outgroup_seq, outgroup_seq_aa, year_windows, seqs_in_window \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplication(outgroup_seq):\n",
    "    \"\"\"\n",
    "    Duplication events (or any insertions) will be signified in the outgroup sequence \n",
    "    by a series of consecutive --- placeholders. Find if there is a duplication in this \n",
    "    evolution of this virus.\n",
    "    \"\"\"\n",
    "    has_dup = False\n",
    "    outgroup_seq_str = str(outgroup_seq)\n",
    "    #if there are ---s in the outgroup_seq, find where they are\n",
    "    #say that insertion/duplication has to be at least 3 codons long\n",
    "    if re.search(\"-{9,}\", outgroup_seq_str):\n",
    "        has_dup=True\n",
    "        \n",
    "        \n",
    "    return has_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_duplications(outgroup_seq, alignment_time_subset):\n",
    "    \"\"\"\n",
    "    Find the position and length of the duplication.\n",
    "    Remove the duplicated region from the outgroup sequence and the every sequence in the alignment.\n",
    "    Evolution on the duplicated region will be considered separately because the outgroup consensus \n",
    "    for this region needs to done from the first timepoint where there are sequences with the duplication\n",
    "    \"\"\"\n",
    "\n",
    "    outgroup_seq_str = str(outgroup_seq)\n",
    "    #find where the duplication is by locating ---s in the outgroup_seq\n",
    "    if re.search(\"-{9,}\", outgroup_seq_str):\n",
    "        dup_start, dup_end = [(x.start(),x.end()) for x in re.finditer(r'-{9,}', outgroup_seq_str)][0]\n",
    "\n",
    "\n",
    "    outgroup_wo_dup = Seq(outgroup_seq_str[:dup_start]+outgroup_seq_str[dup_end:])\n",
    "    outgroup_wo_dup_aa = outgroup_wo_dup.translate()\n",
    "\n",
    "    # remove the duplicated portion from the main alignment\n",
    "    alignment_time_subset_wo_dup = {}\n",
    "    for dates, strain_seqs in alignment_time_subset.items():\n",
    "        strain_seqs_wo_dup = [Seq(str(x)[:dup_start]+str(x)[dup_end:]) for x in strain_seqs]\n",
    "        alignment_time_subset_wo_dup[dates] = strain_seqs_wo_dup\n",
    "    \n",
    "        \n",
    "    \n",
    "    return outgroup_wo_dup, outgroup_wo_dup_aa, alignment_time_subset_wo_dup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_codon_fixations(alignment_sequences, outgroup_seq, midfreq_high):\n",
    "    \"\"\"\n",
    "    For each time window, find if any mutations have fixed \n",
    "    (or nearly fixed, meaning reach a frequency exceeding midfreq_high).\n",
    "    Find whether those mutations are nonsynonymous or synonymous.\n",
    "    Keep a count of fixations/near-fixations at each codon\n",
    "    \"\"\"\n",
    "    \n",
    "    #divide outgroup_seq into codons\n",
    "    outgroup_codons = get_codons(outgroup_seq)\n",
    "    \n",
    "\n",
    "    #initiate arrays to record fixations (or near-fixations) at all codons in alignment\n",
    "    #keep track of this for both nonsynonymous and synonymous mutations\n",
    "    nonsynonymous_fixations = np.zeros(len(outgroup_codons))\n",
    "    synonymous_fixations = np.zeros(len(outgroup_codons))\n",
    "        \n",
    "\n",
    "    for years, alignment_seqs in alignment_sequences.items():\n",
    "  \n",
    "        #look for fixations in each time window\n",
    "        nonsyn_fixations_in_window, syn_fixations_in_window, fixed_codons = walk_through_codons(outgroup_codons, \n",
    "                                                                                                alignment_seqs, midfreq_high)\n",
    "        nonsynonymous_fixations += nonsyn_fixations_in_window\n",
    "        synonymous_fixations += syn_fixations_in_window\n",
    "        \n",
    "        #update outgroup_seq at codons that have fixed mutations \n",
    "        for pos, seq in fixed_codons.items():\n",
    "            outgroup_codons[pos] = seq\n",
    "    \n",
    "\n",
    "    return nonsynonymous_fixations, synonymous_fixations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codons(seq):\n",
    "    \"\"\"\n",
    "    Split the sequence up into a list of codons\n",
    "    Return an error if not divisble by 3\n",
    "    \"\"\"\n",
    "    if len(seq) %3 != 0:\n",
    "        print('Sequence not divisible by 3. Check specific location')\n",
    "    \n",
    "    \n",
    "    codon_list = []\n",
    "    for i in range(0, len(seq), 3):\n",
    "        codon_list.append(seq[i:i+3])\n",
    "    return codon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mutation_fixations(pos, outgroup_codon, alignment_codons, midfreq_high):\n",
    "    \"\"\"\n",
    "    At a given codon position, find whether any mutations occurred, \n",
    "    and if so what frequency they are at in the population\n",
    "    \n",
    "    Classify mutations that reach between midfreq_high and 100% as fixations\n",
    "    \"\"\" \n",
    "\n",
    "    #only consider unabiguous sequencing\n",
    "    alignment_codons = [x for x in alignment_codons if set('AGCT').intersection(set(str(x))) == set(str(x))]\n",
    "\n",
    "    #get a count of the different codon sequences observed at this position\n",
    "    codon_seq_counts = Counter(alignment_codons)\n",
    "    codon_seqs = list(codon_seq_counts.keys())\n",
    "    codon_freqs = {c: (codon_seq_counts[c] / len(alignment_codons)) for c in codon_seq_counts}\n",
    "\n",
    "    \n",
    "    #all codons are the same in the alignment\n",
    "    if len(codon_seqs)==1:\n",
    "        #check if they are the same as the outgroup\n",
    "        #or whether they are a fixed mutation\n",
    "        if outgroup_codon==codon_seqs[0]:\n",
    "            site_type = 'no_fixation'\n",
    "        #or whether they are a fixed mutation\n",
    "        elif outgroup_codon!=codon_seqs[0]:\n",
    "            site_type = 'fixation'\n",
    "            fixed_codon = codon_seqs[0]\n",
    "            \n",
    "    #if there are multiple codon sequences observed at this position, \n",
    "    #see if there are any mutations present at a frequency of midfreq_high or higher\n",
    "    elif len(codon_seqs)!=1:\n",
    "        #default is no fixation, can be overwritten if one codon is present at high freq and is a mutation\n",
    "        site_type = 'no_fixation'\n",
    "        for cod in codon_seqs:\n",
    "            #check whether any of the codon sequences are present at high enough frequency\n",
    "            if codon_freqs[cod] >= midfreq_high:\n",
    "                #check if it is a mutation\n",
    "                if cod != outgroup_codon:\n",
    "                    site_type = 'fixation'\n",
    "                    fixed_codon = cod\n",
    "\n",
    "\n",
    "    # check if fixation was synonymous or nonsynonymous                \n",
    "    if site_type == 'fixation':\n",
    "        outgroup_aa = Seq(outgroup_codon).translate()\n",
    "        alignment_codon_aa = Seq(fixed_codon).translate()\n",
    "        if outgroup_aa == alignment_codon_aa:\n",
    "            fixation_type = 'synonymous'\n",
    "        elif outgroup_aa != alignment_codon_aa:\n",
    "            fixation_type = 'nonsynonymous'\n",
    "    elif site_type == 'no_fixation':\n",
    "        fixation_type = None\n",
    "        fixed_codon = None\n",
    "    \n",
    "    return fixation_type, fixed_codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_codons(outgroup_codons, alignment_seqs, midfreq_high):\n",
    "    \"\"\"\n",
    "    Walk through each codon in each sequence of the alignment and determine whether \n",
    "    there was a synonymous mut, nonsynonymous mut or neither\n",
    "    \"\"\"\n",
    "    \n",
    "    #list of codons in alignment organized as [['ATG','ATG','ATG'],['TAG','TAG','TAG']]\n",
    "    alignment_codons = [[] for x in outgroup_codons]\n",
    "    for seq in alignment_seqs:\n",
    "        isolate_codons = get_codons(seq)\n",
    "        for i in range(len(isolate_codons)):\n",
    "            alignment_codons[i].append(str(isolate_codons[i]))  \n",
    "            \n",
    "    \n",
    "    #initialize arrays to count fixations at each site \n",
    "    nonsyn_fixations_in_window = np.zeros(len(outgroup_codons))\n",
    "    syn_fixations_in_window = np.zeros(len(outgroup_codons))\n",
    "    \n",
    "    #initialize dictionary to keep track of codons {pos:codon seq} that have fixed during this time window, \n",
    "    #so that outgroup_seq can be updated\n",
    "    fixed_codons = {}\n",
    "    \n",
    "    #walk through sequence codon by codon\n",
    "    for i in range(len(outgroup_codons)):\n",
    "        #only consider unabiguous sequencing\n",
    "        if set('AGCT').intersection(set(str(outgroup_codons[i]))) == set(str(outgroup_codons[i])):\n",
    "            #find fixations or near-fixations\n",
    "            fixation_type, fixed_codon_seq = find_mutation_fixations(i, outgroup_codons[i], \n",
    "                                                                     alignment_codons[i], midfreq_high)\n",
    "            if fixed_codon_seq!=None:\n",
    "                fixed_codons[i] = fixed_codon_seq\n",
    "            if fixation_type== 'nonsynonymous':\n",
    "                nonsyn_fixations_in_window[i]+=1\n",
    "            elif fixation_type== 'synonymous':\n",
    "                syn_fixations_in_window[i]+=1\n",
    "                    \n",
    "    return nonsyn_fixations_in_window, syn_fixations_in_window, fixed_codons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for location, look at the start and end numbers from the reference file and use [(start-1), end]\n",
    "def main(virus, subtype, gene, location, coordinate_system, \n",
    "         window=3, min_seqs=3, year_max=False, year_min=False, midfreq_high=0.75):\n",
    "    \"\"\"\n",
    "    Count the number of fixations at each codon and save this as a csv file\n",
    "    \"\"\"\n",
    "    (virus_time_subset, alignment_time_subset, outgroup_seq, \n",
    "     outgroup_seq_aa, year_windows, seqs_in_window) = subset_alignment(virus, subtype, gene, \n",
    "                                                                       location, window, min_seqs, \n",
    "                                                                       year_max, year_min)\n",
    "    \n",
    "    nonsynonymous_fixations, synonymous_fixations = count_codon_fixations(alignment_time_subset, outgroup_seq, midfreq_high)\n",
    "    \n",
    "    #turn arrays into dataframe with count of fixations at residue\n",
    "    sites_with_nonsyn_fixation = []\n",
    "    sites_with_syn_fixation = []\n",
    "    \n",
    "    for x in range(len(nonsynonymous_fixations)):\n",
    "        #rsv has duplication- need to make sure coordinates are consistent with this\n",
    "        #since the duplication was removed from the alignment, coordinates after the duplication need to be adjusted\n",
    "        codon = x\n",
    "        if virus=='rsv':\n",
    "            if subtype=='a':\n",
    "                if x>=284:\n",
    "                    codon = x+24\n",
    "            elif subtype=='b':\n",
    "                if x>=260:\n",
    "                    codon = x+20\n",
    "        \n",
    "        #change coordinate system to make sense with coordinates in auspice and the pdb structure files\n",
    "        if coordinate_system== 'relative_to_atg_generef':\n",
    "            sites_with_nonsyn_fixation.append({'codon':int(codon+location[0]/3+1), \n",
    "                                               'nonsyn_fixations': int(nonsynonymous_fixations[x])})\n",
    "            sites_with_syn_fixation.append({'codon':int(codon+location[0]/3+1), \n",
    "                                            'syn_fixations': int(synonymous_fixations[x])})\n",
    "        elif coordinate_system== 'relative_to_subunit':\n",
    "            sites_with_nonsyn_fixation.append({'codon':int(codon+1), \n",
    "                                       'nonsyn_fixations': int(nonsynonymous_fixations[x])})\n",
    "            sites_with_syn_fixation.append({'codon':int(codon+1), \n",
    "                                'syn_fixations': int(synonymous_fixations[x])})\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    nonsyn_fixations_df = pd.DataFrame(sites_with_nonsyn_fixation)\n",
    "    syn_fixations_df = pd.DataFrame(sites_with_syn_fixation)\n",
    "    \n",
    "    if subtype:\n",
    "        nonsyn_fixations_df.to_csv(f'adaptive_loci_results/fixations_per_site/results/{virus}_{subtype}_{gene}_nonsyn_fixations.csv', index=False)\n",
    "        syn_fixations_df.to_csv(f'adaptive_loci_results/fixations_per_site/results/{virus}_{subtype}_{gene}_syn_fixations.csv', index=False)\n",
    "    else: \n",
    "        nonsyn_fixations_df.to_csv(f'adaptive_loci_results/fixations_per_site/results/{virus}_{gene}_nonsyn_fixations.csv', index=False)\n",
    "        syn_fixations_df.to_csv(f'adaptive_loci_results/fixations_per_site/results/{virus}_{gene}_syn_fixations.csv', index=False)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to best deal with ambiguous sequencing? \n",
    "#Noticed that some mutations called by auspice (like 229E 89) do not show up here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('229e', None, 'spike', [45,3522], coordinate_system='relative_to_atg_generef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('oc43', 'a', 'spike', [39,4086], coordinate_system='relative_to_atg_generef', window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('nl63', None, 'spike', [45,4071], coordinate_system='relative_to_atg_generef', window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('h3n2', None, 'ha', [48,1698], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('h1n1pdm', None, 'ha', [71,1718], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('vic', None, 'ha', [56,1769], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('yam', None, 'ha', [56,1766], coordinate_system='relative_to_subunit', year_min=1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('rsv', 'a', 'g', [4680,5646], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('rsv', 'b', 'g', [4689,5649], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('measles', None, 'h', [7270,9124], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('mumps', None, 'hn', [6550,8299], coordinate_system='relative_to_subunit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('dengue', 'denv2_AA', 'e', [936,2421], coordinate_system='relative_to_subunit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
