{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/katekistler/anaconda3/envs/nextstrain/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from augur.utils import json_to_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "import collections\n",
    "import math\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download tree json\n",
    "tree_url = \"https://data.nextstrain.org/ncov_global.json\"\n",
    "\n",
    "tree_json = requests.get(tree_url).json()\n",
    "\n",
    "#Put tree in Bio.Phylo format\n",
    "tree_ncov = json_to_tree(tree_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "with open('../../seasonal-cov/229e/auspice/seasonal_corona_229e_spike.json') as json_handle:\n",
    "    json_tree_229e = json.load(json_handle)\n",
    "\n",
    "tree_229e = json_to_tree(json_tree_229e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for bhatt clades on Rhino... but can't use augur there\n",
    "\n",
    "def find_clades(tree):\n",
    "    \n",
    "    all_clades_and_parents = []\n",
    "    \n",
    "    for node in tree.find_clades():\n",
    "\n",
    "        if not node.is_terminal():\n",
    "            children = [child.name for child in node.get_terminals()]\n",
    "            all_clades_and_parents.append({'parent': node.name, 'children': children})\n",
    "\n",
    "    \n",
    "    with open('all_clades_and_parents.json', 'w') as fout:\n",
    "        json.dump(all_clades_and_parents, fout)\n",
    "    \n",
    "#     return all_clades_and_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-839771e229ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclade_nodes_by_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_clades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"clade_membership\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mclade_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clade_membership\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "clade_nodes_by_name = {}\n",
    "for node in tree.find_clades(terminal=False):\n",
    "    if \"clade_membership\" in node.node_attrs:\n",
    "        clade_name = node.node_attrs[\"clade_membership\"][\"value\"]\n",
    "\n",
    "        clade_nodes_by_name[node.name] = clade_name\n",
    "        \n",
    "with open('clades_by_node_name.json', 'w') as file_out:\n",
    "    json.dump(clade_nodes_by_name, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_clades(tree_ncov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_individual_mut_occurence(tree):\n",
    "    all_spike_mutation_occurences = []\n",
    "    tree_tips = tree.get_terminals()\n",
    "    tree_internals = tree.get_nonterminals()\n",
    "    all_tree_nodes = tree_tips+tree_internals\n",
    "    \n",
    "    num_branchs = len(all_tree_nodes)\n",
    "\n",
    "    for node in all_tree_nodes:\n",
    "        if len(node.get_terminals())>=10:\n",
    "            if hasattr(node, \"branch_attrs\") and \"mutations\" in node.branch_attrs:\n",
    "                if \"S\" in node.branch_attrs[\"mutations\"]:   \n",
    "                    all_spike_mutation_occurences += node.branch_attrs[\"mutations\"][\"S\"]\n",
    "    \n",
    "    #create count of number of times each spike mutation has happened on tree\n",
    "    spike_mut_count = collections.Counter(all_spike_mutation_occurences)\n",
    "    \n",
    "    #normalize this by number of branchs on tree\n",
    "    spike_mut_freq = {x:y/num_branchs for x,y in spike_mut_count.items()}\n",
    "    \n",
    "    return spike_mut_count, spike_mut_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent(tree, child_clade):\n",
    "    node_path = tree.get_path(child_clade)\n",
    "    return node_path\n",
    "\n",
    "def tally_pair_occurences(tree):\n",
    "    \n",
    "    #all paths from root to tip\n",
    "    all_paths = []\n",
    "    \n",
    "\n",
    "    #dictionary spike muts at each branch\n",
    "    all_branchs_spikemuts = {}\n",
    "\n",
    "    for node in tree.find_clades():\n",
    "        if len(node.get_terminals())>=10:\n",
    "            node_path = get_parent(tree, node)\n",
    "            #path from root to tip, designated by node names\n",
    "            node_names_path = [x.name for x in node_path]\n",
    "            #append this to a list of all paths from root to tip\n",
    "            all_paths.append(node_names_path)\n",
    "\n",
    "            #find spike muts along this path\n",
    "            path_spikemuts = []\n",
    "            for y in node_path:\n",
    "                if hasattr(y, \"branch_attrs\") and \"mutations\" in y.branch_attrs:\n",
    "                    if \"S\" in y.branch_attrs[\"mutations\"]:   \n",
    "                        if y.name not in all_branchs_spikemuts.keys():\n",
    "                            all_branchs_spikemuts[y.name] = y.branch_attrs[\"mutations\"][\"S\"]\n",
    "\n",
    "        \n",
    "        \n",
    "    #keep track of paths on the tree already considered\n",
    "    traveled_segments = []\n",
    "    \n",
    "    #find all pairs of segments that occur along path of tree, without re-counting basal segments of the path\n",
    "    all_branch_pairs = []\n",
    "    \n",
    "    for path in all_paths:\n",
    "        untraveled_segments = []\n",
    "        #find portion of the path that has already been traveled, and new portion\n",
    "        for y in range(len(path)):\n",
    "            while path[:y+1] not in traveled_segments:\n",
    "                traveled_segments.append(path[:y+1])\n",
    "                untraveled_segments+=path[y:]\n",
    "        \n",
    "\n",
    "        #make pairs between only the new segments of path with all other parts of path\n",
    "        untraveled_segment_pairs = itertools.product(untraveled_segments, path)\n",
    "        \n",
    "        for pair in untraveled_segment_pairs:\n",
    "            if pair[0] != pair [1]:\n",
    "                all_branch_pairs.append(pair)\n",
    "                \n",
    "    #convert branch pairs into mutation pairs, some branchs may have multiple mutations, \n",
    "    #leading to multiple mutation pairs for that branch pair   \n",
    "    all_mutation_pairs = []\n",
    "    \n",
    "    for branch_pair in all_branch_pairs:\n",
    "        #only care if both branchs have spike mutations on them\n",
    "        if branch_pair[0] in all_branchs_spikemuts.keys() and branch_pair[1] in all_branchs_spikemuts.keys():\n",
    "            muts_branch0 = all_branchs_spikemuts[branch_pair[0]]\n",
    "            muts_branch1 = all_branchs_spikemuts[branch_pair[1]]\n",
    "            muts_pairs = itertools.product(muts_branch0, muts_branch1)\n",
    "            for mut_pair in muts_pairs:\n",
    "                all_mutation_pairs.append(mut_pair)\n",
    "    \n",
    "    #add pairs that occur on same branch\n",
    "    for k,v in all_branchs_spikemuts.items():\n",
    "        if len(v)>=2:\n",
    "            branch_pairs = itertools.combinations(v, 2)\n",
    "            for bp in branch_pairs:\n",
    "                all_mutation_pairs.append(bp)\n",
    "            \n",
    "\n",
    "\n",
    "    #number of paths from root to tip\n",
    "    num_paths = len(all_paths)\n",
    "    \n",
    "    count_mutation_pairs = collections.Counter(all_mutation_pairs)\n",
    "    \n",
    "    spike_pairs_freq = {x:y/num_paths for x,y in count_mutation_pairs.items()}\n",
    "\n",
    "\n",
    "    return count_mutation_pairs, spike_pairs_freq \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_enrichment_freq(tree, pair_min = 2):\n",
    "    \n",
    "    spike_mut_count, spike_mut_freq = tally_individual_mut_occurence(tree)\n",
    "    count_mutation_pairs, spike_pairs_freq = tally_pair_occurences(tree)\n",
    "    \n",
    "    enrichment_scores = []\n",
    "    \n",
    "    #not sure if this is the right way to do this\n",
    "    for pair, pair_freq in spike_pairs_freq.items():\n",
    "        #only consider pairs that occur at least pair_min times on tree\n",
    "        if count_mutation_pairs[pair] >= pair_min:\n",
    "\n",
    "            mut0 = pair[0]\n",
    "            mut1 = pair[1]\n",
    "            freq0 = spike_mut_freq[mut0]\n",
    "            freq1 = spike_mut_freq[mut1]\n",
    "\n",
    "            enrichment = pair_freq / (freq0*freq1)\n",
    "            enrichment_scores.append({'pair': pair, 'enrichment_score': enrichment, 'pair_freq': pair_freq})\n",
    "    \n",
    "    enrichment_df = pd.DataFrame(enrichment_scores)\n",
    "    print(enrichment_df.nlargest(20, 'enrichment_score'))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pair  enrichment_score  pair_freq\n",
      "9   (G142D, E484Q)      55037.284615   0.005495\n",
      "18   (G142D, T19R)      44029.827692   0.004396\n",
      "19  (G142D, E156-)      44029.827692   0.004396\n",
      "20  (G142D, F157-)      44029.827692   0.004396\n",
      "21  (G142D, R158G)      44029.827692   0.004396\n",
      "24  (G142D, Q484E)      44029.827692   0.004396\n",
      "58    (L5F, A570D)      36691.523077   0.002198\n",
      "61    (L5F, S982A)      36691.523077   0.002198\n",
      "0   (N439K, D614G)      27518.642308   0.002198\n",
      "1    (H69-, D614G)      27518.642308   0.004396\n",
      "2    (V70-, D614G)      27518.642308   0.004396\n",
      "3   (P681H, D614G)      27518.642308   0.007692\n",
      "16  (D950N, D614G)      27518.642308   0.002198\n",
      "17  (T478K, D614G)      27518.642308   0.002198\n",
      "25  (A222V, D614G)      27518.642308   0.002198\n",
      "34  (Y144-, D614G)      27518.642308   0.004396\n",
      "35  (E484K, D614G)      27518.642308   0.008791\n",
      "37  (T716I, D614G)      27518.642308   0.002198\n",
      "38   (P26S, D614G)      27518.642308   0.002198\n",
      "39  (L241-, D614G)      27518.642308   0.002198\n"
     ]
    }
   ],
   "source": [
    "calc_enrichment_freq(tree_ncov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_enrichment_count(tree, ind_min=3, pair_min=3):\n",
    "    \n",
    "    spike_mut_count, spike_mut_freq = tally_individual_mut_occurence(tree)\n",
    "    count_mutation_pairs, spike_pairs_freq = tally_pair_occurences(tree)\n",
    "    \n",
    "    enrichment_scores = []\n",
    "    \n",
    "    #not sure if this is the right way to do this\n",
    "    for pair, pair_count in count_mutation_pairs.items():\n",
    "        mut0 = pair[0]\n",
    "        mut1 = pair[1]\n",
    "        count0 = spike_mut_count[mut0]\n",
    "        count1 = spike_mut_count[mut1]\n",
    "        \n",
    "        #only consider pairs that were observed at least pair_min number of times\n",
    "        #and where the individual mutations occurred at least ind_min number of times accross the tree\n",
    "        if pair_count>=pair_min:\n",
    "            if count0 >= ind_min and count1 >= ind_min:\n",
    "                enrichment = pair_count / (count0*count1)\n",
    "                enrichment_scores.append({'pair': pair, 'enrichment_score': enrichment,\n",
    "                                          'pair_count': pair_count, 'scoring': 'together',\n",
    "                                          'individual_mut_count0': count0, 'individual_mut_count1': count1})\n",
    "#             if count0 >= ind_min:\n",
    "#                 enrichment0 = pair_count / count0\n",
    "#                 if mut1!= 'D614G':\n",
    "#                     enrichment_scores.append({'pair': pair, 'enrichment_score': enrichment0,\n",
    "#                                               'pair_count': pair_count, 'scoring': '0only',\n",
    "#                                               'individual_mut': mut0, 'individual_mut_count': count0})\n",
    "#             if count1 >= ind_min:\n",
    "#                 enrichment1 = pair_count / count1\n",
    "#                 enrichment_scores.append({'pair': pair, 'enrichment_score': enrichment1, 'scoring': '1only',\n",
    "#                                           'pair_count': pair_count, 'individual_mut': mut1, \n",
    "#                                           'individual_mut_count': count1})\n",
    "    \n",
    "    enrichment_df = pd.DataFrame(enrichment_scores)\n",
    "    print(enrichment_df.nlargest(50, 'enrichment_score'))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pair  enrichment_score  pair_count   scoring  \\\n",
      "1  (G142D, P681R)          0.333333           5  together   \n",
      "5    (H69-, V70-)          0.250000           4  together   \n",
      "0  (G142D, L452R)          0.200000           5  together   \n",
      "3   (T95I, P681R)          0.166667           3  together   \n",
      "6  (Y144-, P681H)          0.107143           3  together   \n",
      "2   (T95I, L452R)          0.100000           3  together   \n",
      "4  (Y144-, E484K)          0.093750           3  together   \n",
      "7  (E484K, N501Y)          0.093750           3  together   \n",
      "\n",
      "   individual_mut_count0  individual_mut_count1  \n",
      "1                      5                      3  \n",
      "5                      4                      4  \n",
      "0                      5                      5  \n",
      "3                      6                      3  \n",
      "6                      4                      7  \n",
      "2                      6                      5  \n",
      "4                      4                      8  \n",
      "7                      8                      4  \n"
     ]
    }
   ],
   "source": [
    "calc_enrichment_count(tree_ncov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
