{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee84c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be325ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the insertions from Step2 that are found as insertions of ON1 seqs relative to a reference with a duplication\n",
    "#and for non-ON1 sequences compared to a reference without a duplication\n",
    "#use these in step3 to infer ancestral insertions\n",
    "\n",
    "#need to merge the insertions tsvs for ON1 and non-ON1 sequences\n",
    "#but need to adjust the positions of the non-ON1 sequences to account for the duplication\n",
    "#this means adjusting all positions after the duplication by 72nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc862161",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_seq_dict = {'a':'GTCAAGAGGAAACCCTCCACTCAACCACCTCCGAAGGCTATCTAAGCCCATCACAAGTCTATACAACATCCG', \n",
    "                'b': 'ACAGAAAGAGACACCAGCACCTCACAATCCACTGTGCTCGACACAACCACATCAAAACAC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128eccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find where duplication placeholdher should go\n",
    "def find_duplication_location(subtype):\n",
    "    dup_ref_fasta = f'../config/rsv_{subtype}_step3_reference.fasta'\n",
    "    \n",
    "    dup_seq = dup_seq_dict[subtype]\n",
    "\n",
    "    with open(dup_ref_fasta, 'r') as handle:\n",
    "        for ref in SeqIO.parse(handle, 'fasta'):\n",
    "            loc_template = str(ref.seq).find(dup_seq.lower())\n",
    "            start_dup = loc_template+len(dup_seq)\n",
    "            #check that this is the same seq as above\n",
    "            dup_seq_in_ref = str(ref.seq)[start_dup:start_dup+len(dup_seq)]\n",
    "#             print(dup_seq_in_ref==dup_seq.lower())\n",
    "            \n",
    "    return start_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef849067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the postitions of insertions inferred in step2 for the non-duplication strains need to be adjusted\n",
    "#if the occurred after the duplication\n",
    "def adjust_insertion_positions(subtype):\n",
    "    start_dup = find_duplication_location(subtype)\n",
    "    \n",
    "    dup_seq = dup_seq_dict[subtype]\n",
    "    \n",
    "    #read in insertions tsv from Step2\n",
    "    other_insertions = pd.read_csv(f'../../rsv_step2/results/insertions_{subtype}_other.tsv')\n",
    "\n",
    "    #remove lines with null entries\n",
    "    other_insertions = other_insertions[other_insertions['insertions'].notnull()]\n",
    "\n",
    "    for k,v in other_insertions.iterrows():\n",
    "        list_of_insertions = v['insertions'].split(';')\n",
    "\n",
    "        new_insertions = []\n",
    "        for i in list_of_insertions:\n",
    "            insertion_pos = int(i.split(':')[0])\n",
    "            if insertion_pos>=start_dup:\n",
    "                pos_adjusted = insertion_pos+len(dup_seq)\n",
    "                ins_nts = i.split(':')[1]\n",
    "                ins_adjusted = f'{pos_adjusted}:{ins_nts}'\n",
    "                new_insertions.append(ins_adjusted)\n",
    "            else:\n",
    "                new_insertions.append(i)\n",
    "        v['insertions'] = ';'.join(new_insertions)\n",
    "        \n",
    "    return other_insertions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2d0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_insertion_tsvs(subtype):\n",
    "    other_insertions = adjust_insertion_positions(subtype)\n",
    "    \n",
    "    #read in ba/on1 insertions tsv from Step2\n",
    "    dup_insertions = pd.read_csv(f'../../rsv_step2/results/insertions_{subtype}_dup.tsv')\n",
    "    \n",
    "    all_insertions_step2 = other_insertions.append(dup_insertions, ignore_index=True)\n",
    "\n",
    "    all_insertions_step2.to_csv(f'insertions_{subtype}_step2.tsv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452dd62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/6938g_6s199gxxswt2nf7w500000gn/T/ipykernel_63130/1481910198.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_insertions_step2 = other_insertions.append(dup_insertions, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "merge_insertion_tsvs('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a8f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/6938g_6s199gxxswt2nf7w500000gn/T/ipykernel_63130/1481910198.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_insertions_step2 = other_insertions.append(dup_insertions, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "merge_insertion_tsvs('b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
